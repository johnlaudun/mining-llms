{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2abc7877",
   "metadata": {},
   "source": [
    "# 5 - Ground Truth Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb86a26c",
   "metadata": {},
   "source": [
    "I'm skipping past building a semantic vector space based on Reddit for now, and going straight to ground truth verification using search results. \n",
    "\n",
    "* [pistocop/subreddit-comments-dl: Download subreddit comments](https://github.com/pistocop/subreddit-comments-dl)\n",
    "* [serpapi documentation on PyPI](https://pypi.org/project/serpapi/)\n",
    "* [My SerpApi Dashboard](https://serpapi.com/searches)\n",
    "* [Google Gemini](https://gemini.google.com/app/aa2876187db79f27) notes.\n",
    "\n",
    "To run **all-MiniLM-L6-v2** locally: [StackOverflow](https://stackoverflow.com/questions/65419499/download-pre-trained-sentence-transformers-model-locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9883cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS, KEYS, MODELS\n",
    "from serpapi import GoogleSearch\n",
    "import json\n",
    "from collections import Counter\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load API key\n",
    "keys = json.load(open(\"../apikeys.json\"))\n",
    "SERP_API_KEY = keys[\"SerpApi\"][\"key\"]\n",
    "\n",
    "# Load model (all-MiniLM-L6-v2 is fast and accurate)\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model = SentenceTransformer('../models/BERT-all-mpnet-base-v2')\n",
    "\n",
    "# SAVE MODEL (for offline use)\n",
    "# model.save('../models/BERT-all-mpnet-base-v2')\n",
    "# THEN TO LOAD IT AGAIN:\n",
    "# model = SentenceTransformer(modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b286c5",
   "metadata": {},
   "source": [
    "## Loading Results & Getting Rid of Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff7cd1",
   "metadata": {},
   "source": [
    "The first thing to do is to re-use some code to load the saved results of queries and then to find the repetitions. After that, we can work on merging similar proverbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "334ed272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD FILE\n",
    "with open('outputs/di-5000-3.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# EXTRACT JUST THE TEXT FROM THE DATA\n",
    "texts = [entry['text'] for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd6b8acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Proverbs: 1075\n",
      "Total Repetitions: 3925\n"
     ]
    }
   ],
   "source": [
    "# A QUICK LOOK\n",
    "\n",
    "# COUNT OCCURRENCES\n",
    "counts = Counter(texts)\n",
    "\n",
    "# FIND PROVERBS THAT APPEARED MORE THAN ONCE\n",
    "duplicates = {text: count for text, count in counts.items() if count > 1}\n",
    "print(f\"Unique Proverbs: {len(counts)}\")\n",
    "print(f\"Total Repetitions: {sum(duplicates.values()) - len(duplicates)}\")\n",
    "\n",
    "# TO SEE REPETITIONS\n",
    "# print(\"\\nMost Frequent Repetitions:\")\n",
    "# for text, count in sorted(duplicates.items(), key=lambda x: x[1], reverse=True)[30:40]:\n",
    "#     print(f\"[{count}x] {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517190af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE EXACT DUPLICATES & SORT BY LENGTH \n",
    "# sorting = shortest version is \"anchor\" for consolidation\n",
    "deduped = list(set(texts)) # If first method is used\n",
    "uniques = sorted(deduped, key=len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e35b17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n",
      "1075\n"
     ]
    }
   ],
   "source": [
    "print(len(duplicates))\n",
    "print(len(uniques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa4026f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Original Count: 1075 | Final Count: 34 ---\n",
      "‚úì Comparison is the thief of joy.\n",
      "‚úì The struggle is real, but so is the wifi signal.\n",
      "‚úì No one is actually happy with their life choices.\n",
      "‚úì If you're not paying for a product, you are the product.\n",
      "‚úì If you're not having anxiety, you're not paying attention.\n",
      "‚úì If you don't post about it on social media, it didn't happen.\n",
      "‚úì The struggle is real and I'm not even getting paid to have it.\n",
      "‚úì The most unhinged people are the ones with the most mundane lives.\n",
      "‚úì If you're not living on the edge, you're taking up too much space.\n",
      "‚úì The most viewed content is always the thing you're trying to avoid.\n",
      "‚úì If you're not embarrassing yourself online you're not living enough.\n",
      "‚úì The most unpopular people are the ones who speak the hardest truths.\n",
      "‚úì The most unproductive thing you can do on the internet is read comments.\n",
      "‚úì The most productive people don't have more time, they just waste less of it.\n",
      "‚úì If you're not having to adult today, you've probably done it wrong yesterday.\n",
      "‚úì No one really knows what they're doing and we're all just winging it together.\n",
      "‚úì The most popular person on social media is often the most lonely in real life.\n",
      "‚úì The most toxic thing is being told you're overreacting when you're really not.\n",
      "‚úì The highlight of your day is probably someone else living their life on the internet.\n",
      "‚úì The most important thing to remember is that nobody posts their worst day on Instagram.\n",
      "‚úì The most unhinged comments are always from people who spent 10 minutes googling the topic.\n",
      "‚úì The struggle is real and it's okay to not be okay, but also don't forget to adult sometimes.\n",
      "‚úì The most important thing to remember is that everyone's highlight reel is not your real life.\n",
      "‚úì The most efficient way to double your money is to fold it in half and put it back in your pocket.\n",
      "‚úì The most honest thing you can say to a person online is that you're not going to read their essay.\n",
      "‚úì The most unfiltered version of someone is usually on their first tweet and their last Instagram post.\n",
      "‚úì The most honest thing you can say on a first date is that you're probably going to ghost me eventually.\n",
      "‚úì The most honest thing a generation Z-er will say to your face is that your content is lowkey problematic.\n",
      "‚úì The most important thing you can do for your mental health is to delete social media apps off your phone.\n",
      "‚úì The most stressful thing about being an adult is pretending you have a clue what's going on when you really don't.\n",
      "‚úì The most important thing to remember is that you're probably not as happy or successful as people make you out to be on the internet.\n",
      "‚úì The most viral posts are often created not to inform or educate, but to validate the preconceived notions of the people who share them.\n",
      "‚úì The more you scroll through your feeds, the more you'll realize everyone's an expert on everything and nobody actually knows what's going on.\n",
      "‚úì Comparison is the thief of joy, and Instagram is a comparison machine that steals our happiness by making us feel inadequate and insecure about our lives.\n"
     ]
    }
   ],
   "source": [
    "# NOTA BENE: for 1000 proverbs, this takes about ~8 minutes to run\n",
    "\n",
    "# EMPTY LIST TO HOLD LOOP OUTPUT\n",
    "unique_proverbs = []\n",
    "\n",
    "# THRESHOLD FOR SIMILARITY (lower = more aggressive)\n",
    "threshold = 0.50  # Aggressive grouping\n",
    "\n",
    "for current in uniques:\n",
    "    if not unique_proverbs:\n",
    "        unique_proverbs.append(current)\n",
    "        continue\n",
    "    \n",
    "    # Compare current sentence against our accepted unique list\n",
    "    current_emb = model.encode(current, convert_to_tensor=True)\n",
    "    unique_embs = model.encode(unique_proverbs, convert_to_tensor=True)\n",
    "    \n",
    "    scores = util.cos_sim(current_emb, unique_embs)[0]\n",
    "    \n",
    "    # If it's not similar to anything we already have, add it\n",
    "    if max(scores) < threshold:\n",
    "        unique_proverbs.append(current)\n",
    "\n",
    "# Display results\n",
    "print(f\"--- Original Count: {len(uniques)} | Final Count: {len(unique_proverbs)} ---\")\n",
    "for p in unique_proverbs:\n",
    "    print(f\"‚úì {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84c26991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO HAND INSPECT\n",
    "with open('outputs/unique_proverbs-3.txt', 'w') as f:\n",
    "    f.writelines([p + '\\n' for p in unique_proverbs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d1d8ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you're not embarrassing yourself online you're not living enough.\n",
      "The most unpopular people are the ones who speak the hardest truths.\n",
      "The most unproductive thing you can do on the internet is read comments.\n",
      "The most productive people don't have more time, they just waste less of it.\n",
      "If you're not having to adult today, you've probably done it wrong yesterday.\n",
      "No one really knows what they're doing and we're all just winging it together.\n",
      "The most popular person on social media is often the most lonely in real life.\n",
      "The most toxic thing is being told you're overreacting when you're really not.\n",
      "The highlight of your day is probably someone else living their life on the internet.\n",
      "The most important thing to remember is that nobody posts their worst day on Instagram.\n"
     ]
    }
   ],
   "source": [
    "for proverb in unique_proverbs[10:20]:\n",
    "    print(proverb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d900d",
   "metadata": {},
   "source": [
    "Okay, there are interesting proverbs here, and I am tempted to try to find the ones more focused on online life and social media -- perhaps through the use of keywords, like \"post\", \"comment\", \"like\", \"share\", \"follow\", \"subscribe\", \"thread\", \"troll\", \"signal\", \"content.\" Instead, I think I will let it ride and just pass the top N of this list off to SERPAPI to see what it finds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbfc7e9",
   "metadata": {},
   "source": [
    "## Search / Validate\n",
    "\n",
    "Having whittled down the responses from the LLM to a manageable number of unique proverbs, we can now use SerpApi to search for each proverb and see if there are any results. If there are results, we can assume that the proverb is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aab51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_extant(phrase):\n",
    "    \"\"\"\n",
    "    Checks the web for the phrase and looks for 'canonical' markers.\n",
    "    \"\"\"\n",
    "    # TOTAL HIT COUNT CHECK \n",
    "    # (uses exact phrase match)\n",
    "    params = {\n",
    "        \"q\": f'\"{phrase}\"',  # Quoted for exact match\n",
    "        \"engine\": \"google\",\n",
    "        \"api_key\": SERP_API_KEY\n",
    "    }\n",
    "    \n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    \n",
    "    # Extract total results (Google hit count)\n",
    "    total_results = results.get(\"search_information\", {}).get(\"total_results\", 0)\n",
    "    \n",
    "    # TARGETED SITE CHECK \n",
    "    # We check if the phrase appears on known authority sites\n",
    "    authority_sites = [\"oxfordreference.com\", \"phrases.org.uk\", \"theidioms.com\"]\n",
    "    site_query = f'\"{phrase}\" site:' + \" OR site:\".join(authority_sites)\n",
    "    \n",
    "    site_params = {**params, \"q\": site_query}\n",
    "    site_search = GoogleSearch(site_params)\n",
    "    site_results = site_search.get_dict()\n",
    "    \n",
    "    authority_count = site_results.get(\"search_information\", {}).get(\"total_results\", 0)\n",
    "    \n",
    "    # NOVELTY LOGIC\n",
    "    # High LLM Stability + Low Search Hits = A Discovery\n",
    "    if total_results < 1000 and authority_count == 0:\n",
    "        return {\n",
    "            \"verdict\": \"üåü NOVEL MAXIM\",\n",
    "            \"hits\": total_results,\n",
    "            \"details\": \"High consensus in AI, but virtually zero footprint in human dictionaries.\"\n",
    "        }\n",
    "    elif authority_count > 0:\n",
    "        return {\n",
    "            \"verdict\": \"üìö DOCUMENTED PROVERB\",\n",
    "            \"hits\": total_results,\n",
    "            \"details\": f\"Found on {authority_count} authority websites.\"\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"verdict\": \"üåê COMMON IDIOM\",\n",
    "            \"hits\": total_results,\n",
    "            \"details\": \"Frequently used online but not officially documented as a proverb.\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL TESTS\n",
    "# d1 = verify_external_existence(\"The internet is forever and nothing is ever really deleted.\")\n",
    "# d2 = verify_external_existence(\"If you lurk long enough on any online community, you'll eventually see yourself in a post.\")\n",
    "\n",
    "# print(d1)\n",
    "# print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f6cf8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verdict': 'üåê COMMON IDIOM', 'hits': 2030000, 'details': 'Frequently used online but not officially documented as a proverb.'}\n",
      "{'verdict': 'üåê COMMON IDIOM', 'hits': 2760000, 'details': 'Frequently used online but not officially documented as a proverb.'}\n",
      "{'verdict': 'üìö DOCUMENTED PROVERB', 'hits': 1690000000, 'details': 'Found on 484 authority websites.'}\n",
      "{'verdict': 'üìö DOCUMENTED PROVERB', 'hits': 13700, 'details': 'Found on 986 authority websites.'}\n",
      "{'verdict': 'üìö DOCUMENTED PROVERB', 'hits': 241000000, 'details': 'Found on 5 authority websites.'}\n",
      "{'verdict': 'üìö DOCUMENTED PROVERB', 'hits': 1, 'details': 'Found on 45 authority websites.'}\n",
      "{'verdict': 'üìö DOCUMENTED PROVERB', 'hits': 336000000, 'details': 'Found on 54 authority websites.'}\n",
      "{'verdict': 'üåê COMMON IDIOM', 'hits': 6540000, 'details': 'Frequently used online but not officially documented as a proverb.'}\n",
      "{'verdict': 'üìö DOCUMENTED PROVERB', 'hits': 46600, 'details': 'Found on 10 authority websites.'}\n",
      "{'verdict': 'üìö DOCUMENTED PROVERB', 'hits': 4660000000, 'details': 'Found on 37500 authority websites.'}\n"
     ]
    }
   ],
   "source": [
    "# BUILD A LIST\n",
    "verities = [verify_extant(p) for p in unique_proverbs[0:10]]\n",
    "\n",
    "# What we got?\n",
    "for v in verities:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e30ab9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê COMMON IDIOM (2030000 hits): Comparison is the thief of joy. -- Frequently used online but not officially documented as a proverb.\n",
      "üåê COMMON IDIOM (2760000 hits): The struggle is real, but so is the wifi signal. -- Frequently used online but not officially documented as a proverb.\n",
      "üìö DOCUMENTED PROVERB (1690000000 hits): No one is actually happy with their life choices. -- Found on 484 authority websites.\n",
      "üìö DOCUMENTED PROVERB (13700 hits): If you're not paying for a product, you are the product. -- Found on 986 authority websites.\n",
      "üìö DOCUMENTED PROVERB (241000000 hits): If you're not having anxiety, you're not paying attention. -- Found on 5 authority websites.\n",
      "üìö DOCUMENTED PROVERB (1 hits): If you don't post about it on social media, it didn't happen. -- Found on 45 authority websites.\n",
      "üìö DOCUMENTED PROVERB (336000000 hits): The struggle is real and I'm not even getting paid to have it. -- Found on 54 authority websites.\n",
      "üåê COMMON IDIOM (6540000 hits): The most unhinged people are the ones with the most mundane lives. -- Frequently used online but not officially documented as a proverb.\n",
      "üìö DOCUMENTED PROVERB (46600 hits): If you're not living on the edge, you're taking up too much space. -- Found on 10 authority websites.\n",
      "üìö DOCUMENTED PROVERB (4660000000 hits): The most viewed content is always the thing you're trying to avoid. -- Found on 37500 authority websites.\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(unique_proverbs[0:10]):\n",
    "    v = verities[i]\n",
    "    print(f\"{v['verdict']} ({v['hits']} hits): {p} -- {v['details']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2624b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('outputs/verification-3-0-10.txt', 'w') as f:\n",
    "    for i, p in enumerate(unique_proverbs):\n",
    "        v = verities[i]\n",
    "        f.write(f\"{v['verdict']} ({v['hits']} hits): {p} -- {v['details']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b31d8d",
   "metadata": {},
   "source": [
    "Okay, I just re-ran the search for the same proverbs and burned up whatever number of free credits I have on SerpApi. To improve the possibility of finding interesting results, I think I will filter all my previous responses to include keywords related to social media, life online, etc. I think I will do that in a new notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
